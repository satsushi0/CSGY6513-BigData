{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "146a2ba9",
   "metadata": {},
   "source": [
    "# CSGY-6513 Big Data Final Project\n",
    "The code here is to fetch text data related to stock market from Reddit, and combine them with daily stock return from Yahoo Finance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0eda61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from psaw import PushshiftAPI\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0deccc93",
   "metadata": {},
   "source": [
    "## 1. Fetch Posts from Reddit through its API.\n",
    "We spent more than a week to obtain the posts in this year. To save the partial result, we used pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ef80a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = PushshiftAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "499e262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPushshiftData(after, before, sub, limit):\n",
    "    url = 'https://api.pushshift.io/reddit/search/submission/?'+'size=1000' + '&after='+str(after)+'&before='+str(before) + '&subreddit='+str(sub)\n",
    "    r = requests.get(url)\n",
    "    if r.status_code != 200:\n",
    "        time.sleep(5)\n",
    "        return getPushshiftData(after, before, sub, limit)\n",
    "    else:\n",
    "        return json.loads(r.text)['data']\n",
    "\n",
    "def getCommentsReddit(submissionId):\n",
    "    url = 'https://api.pushshift.io/reddit/comment/search/?'+'link_id=' + submissionId + '&q=*&limit=1000'\n",
    "    r = requests.get(url)\n",
    "    if r.status_code != 200:\n",
    "        time.sleep(5)\n",
    "        return getCommentsReddit(submissionId)\n",
    "    else:\n",
    "        return json.loads(r.text)['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "368ff5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract data from 2022-11-11 20:59:34 to 2022-12-09 23:56:00 ...\n",
      "    11:12 | Current timestamp: 2022-11-12 10:21:57 | #Rows: 1963073\n",
      "    11:34 | Current timestamp: 2022-11-13 23:55:35 | #Rows: 1973558\n",
      "    11:58 | Current timestamp: 2022-11-15 11:48:05 | #Rows: 1982561\n",
      "    12:17 | Current timestamp: 2022-11-16 13:35:16 | #Rows: 1989758\n",
      "    12:32 | Current timestamp: 2022-11-17 22:05:03 | #Rows: 1998777\n",
      "    12:49 | Current timestamp: 2022-11-19 13:20:05 | #Rows: 2009866\n",
      "    13:10 | Current timestamp: 2022-11-21 15:46:51 | #Rows: 2023416\n",
      "    13:30 | Current timestamp: 2022-11-23 06:06:30 | #Rows: 2036230\n",
      "    13:51 | Current timestamp: 2022-11-25 08:13:15 | #Rows: 2047117\n",
      "    14:12 | Current timestamp: 2022-11-27 17:01:23 | #Rows: 2061182\n",
      "    14:32 | Current timestamp: 2022-11-29 14:57:55 | #Rows: 2073603\n",
      "    14:54 | Current timestamp: 2022-11-30 23:57:44 | #Rows: 2085813\n",
      "    15:15 | Current timestamp: 2022-12-02 12:32:45 | #Rows: 2095977\n",
      "    15:34 | Current timestamp: 2022-12-04 19:50:26 | #Rows: 2107848\n",
      "    15:52 | Current timestamp: 2022-12-06 16:45:12 | #Rows: 2119621\n",
      "    16:13 | Current timestamp: 2022-12-07 21:18:53 | #Rows: 2131022\n",
      "    16:35 | Current timestamp: 2022-12-09 06:00:49 | #Rows: 2141097\n"
     ]
    }
   ],
   "source": [
    "# reddit = []\n",
    "reddit = pickle.load(open(\"reddit.pkl\", \"rb\"))\n",
    "# after = int(datetime(2022, 1, 1).replace(tzinfo=timezone(\"US/Eastern\")).timestamp())\n",
    "after = pickle.load(open(\"after.pkl\", \"rb\"))\n",
    "before = int(datetime(2022, 12, 10).replace(tzinfo=timezone(\"US/Eastern\")).timestamp())\n",
    "data = getPushshiftData(after, before, \"wallstreetbets\", 20000)\n",
    "print(f\"Extract data from {datetime.fromtimestamp(after)} to {datetime.fromtimestamp(before)} ...\")\n",
    "timecheck = time.time() - 1000\n",
    "while len(data)>0:\n",
    "    for submission in data:\n",
    "        reddit.append([submission[\"id\"], submission[\"title\"], \"\", datetime.fromtimestamp(submission[\"created_utc\"])])\n",
    "        if submission[\"num_comments\"] > 0:\n",
    "            comments = getCommentsReddit(submission[\"id\"])\n",
    "            for comment in comments:\n",
    "                reddit.append([submission[\"id\"], \"\", comment[\"body\"], datetime.fromtimestamp(comment[\"created_utc\"])])\n",
    "    after = data[-1][\"created_utc\"]+1\n",
    "    if time.time() - timecheck > 900:\n",
    "        pickle.dump(reddit, open(\"reddit.pkl\", \"wb\"))\n",
    "        pickle.dump(after, open(\"after.pkl\", \"wb\"))\n",
    "        h, m = str(datetime.fromtimestamp(time.time()).hour), str(datetime.fromtimestamp(time.time()).minute)\n",
    "        if len(m) == 1:\n",
    "            m = '0' + m\n",
    "        curtime = h + \":\" + m\n",
    "        print(f\"    {curtime} | Current timestamp: {datetime.fromtimestamp(after)} | #Rows: {len(reddit)}\")\n",
    "        timecheck = time.time()\n",
    "    data = getPushshiftData(after, before, \"wallstreetbets\", 20000)\n",
    "pickle.dump(reddit, open(\"reddit.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e666558",
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = '¥'\n",
    "for i in range(len(reddit)):\n",
    "    for j in [1, 2]:\n",
    "        reddit[i][j] = re.sub(sep, ' ', reddit[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74d862ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df = pd.DataFrame(reddit, columns=[\"id\", \"title\", \"comment\", \"timestamp\"])\n",
    "reddit_df[\"time_key\"] = reddit_df[\"timestamp\"].apply(lambda x: x.date())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b976a316",
   "metadata": {},
   "source": [
    "## 2. Extract the Stock Market Data from Yahoo Finance API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7494387",
   "metadata": {},
   "outputs": [],
   "source": [
    "spx = yf.Ticker(\"^GSPC\")\n",
    "spx = spx.history(period=\"5y\")\n",
    "spx[\"SP500\"] = spx[\"Close\"] / spx[\"Close\"].shift(1) - 1\n",
    "spx[\"timestamp\"] = spx.index\n",
    "spx[\"time_key\"] = spx[\"timestamp\"].apply(lambda x: x.date)\n",
    "\n",
    "tsla = yf.Ticker(\"TSLA\")\n",
    "tsla = tsla.history(period=\"5y\")\n",
    "tsla[\"TESLA\"] = tsla[\"Close\"] / tsla[\"Close\"].shift(1) - 1\n",
    "tsla[\"timestamp\"] = tsla.index\n",
    "tsla[\"time_key\"] = tsla[\"timestamp\"].apply(lambda x: x.date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879540c2",
   "metadata": {},
   "source": [
    "## 3. Combine them Together and Export it as CSV File."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8a00f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df = reddit_df.merge(spx[[\"time_key\", \"SP500\"]], how=\"left\", on=\"time_key\")\n",
    "reddit_df = reddit_df.merge(tsla[[\"time_key\", \"TESLA\"]], how=\"left\", on=\"time_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f02db5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>time_key</th>\n",
       "      <th>SP500</th>\n",
       "      <th>TESLA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2147349</th>\n",
       "      <td>zhjbwk</td>\n",
       "      <td></td>\n",
       "      <td>Start auto investing into etf’s also - and rid...</td>\n",
       "      <td>2022-12-09 23:57:10</td>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>-0.00735</td>\n",
       "      <td>0.032345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147350</th>\n",
       "      <td>zhjbwk</td>\n",
       "      <td></td>\n",
       "      <td>Are those 1 week expiry options? Sorry we don’...</td>\n",
       "      <td>2022-12-09 23:56:53</td>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>-0.00735</td>\n",
       "      <td>0.032345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147351</th>\n",
       "      <td>zhjbwk</td>\n",
       "      <td></td>\n",
       "      <td>&amp;gt;If you're looking to maximize your returns...</td>\n",
       "      <td>2022-12-09 23:55:31</td>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>-0.00735</td>\n",
       "      <td>0.032345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147352</th>\n",
       "      <td>zhjbwk</td>\n",
       "      <td></td>\n",
       "      <td>\\n**User Report**| | | |\\n:--|:--|:--|:--\\n**T...</td>\n",
       "      <td>2022-12-09 23:55:23</td>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>-0.00735</td>\n",
       "      <td>0.032345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147353</th>\n",
       "      <td>zhjbwk</td>\n",
       "      <td></td>\n",
       "      <td>Nobody tell him.\\n\\n*I am a bot, and this acti...</td>\n",
       "      <td>2022-12-09 23:55:18</td>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>-0.00735</td>\n",
       "      <td>0.032345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id title                                            comment  \\\n",
       "2147349  zhjbwk        Start auto investing into etf’s also - and rid...   \n",
       "2147350  zhjbwk        Are those 1 week expiry options? Sorry we don’...   \n",
       "2147351  zhjbwk        &gt;If you're looking to maximize your returns...   \n",
       "2147352  zhjbwk        \\n**User Report**| | | |\\n:--|:--|:--|:--\\n**T...   \n",
       "2147353  zhjbwk        Nobody tell him.\\n\\n*I am a bot, and this acti...   \n",
       "\n",
       "                  timestamp    time_key    SP500     TESLA  \n",
       "2147349 2022-12-09 23:57:10  2022-12-09 -0.00735  0.032345  \n",
       "2147350 2022-12-09 23:56:53  2022-12-09 -0.00735  0.032345  \n",
       "2147351 2022-12-09 23:55:31  2022-12-09 -0.00735  0.032345  \n",
       "2147352 2022-12-09 23:55:23  2022-12-09 -0.00735  0.032345  \n",
       "2147353 2022-12-09 23:55:18  2022-12-09 -0.00735  0.032345  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c655b298",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df.to_csv(\"reddit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "743e23e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2147354/2147354 [05:58<00:00, 5989.29it/s] \n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "text_dic = {}\n",
    "for i in tqdm.tqdm(range(len(reddit_df))):\n",
    "    if reddit_df.loc[i, \"time_key\"] in text_dic.keys():\n",
    "        text_dic[reddit_df.loc[i, \"time_key\"]] += \" \" + reddit_df.loc[i, \"title\"] + \" \" + reddit_df.loc[i, \"comment\"]\n",
    "    else:\n",
    "        text_dic[reddit_df.loc[i, \"time_key\"]] = reddit_df.loc[i, \"title\"] + \" \" + reddit_df.loc[i, \"comment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1c91b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
